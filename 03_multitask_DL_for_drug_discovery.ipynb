{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On Tutorial 3: Multitask Deep Learning for Drug Discovery\n",
    "\n",
    "Implemntation of the model described in https://arxiv.org/pdf/1502.02072.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, LSTM, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import MSE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from helpers.extra_metrics import explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 120\n",
    "VAL_SIZE = 20000\n",
    "LEARNING_RATE = .001\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation\n",
    "\n",
    "We will use the [QM9 dataset](http://quantum-machine.org/datasets/):\n",
    "* L. Ruddigkeit, R. van Deursen, L. C. Blum, J.-L. Reymond, Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17, J. Chem. Inf. Model. 52, 2864â€“2875, 2012.\n",
    "* R. Ramakrishnan, P. O. Dral, M. Rupp, O. A. von Lilienfeld, Quantum chemistry structures and properties of 134 kilo molecules, Scientific Data 1, 140022, 2014. [bibtex]\n",
    "\n",
    "The QM9 dataset contains 133885 organic molecules, represented as SMILES strings, with 15 properties each. We will train a regression model to predict all 15 properties in a multitask settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download dataset\n",
    "url = 'https://s3.us-east-2.amazonaws.com/weizmann-dl-workshop/data_qm9.pkl.zip'\n",
    "file_path = 'datasets/qm9.pkl.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('datasets/')\n",
    "r = requests.get(url, auth=('usrname', 'password'), verify=False,stream=True)\n",
    "r.raw.decode_content = True\n",
    "with open(file_path, 'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ONLY IF THE PREVIOUS FAILED TO DOWNLOAD \"\"\"\n",
    "!mkdir -p datasets\n",
    "!wget --no-check-certificate $url -O $file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract dataset\n",
    "with zipfile.ZipFile(file_path, 'r') as file:\n",
    "    file.extractall('datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "data = pd.read_pickle('datasets/data_qm9.pkl')\n",
    "labels = ['A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0', 'U', 'H', 'G', 'Cv']\n",
    "\n",
    "properties = {}\n",
    "for i, key in enumerate(labels):\n",
    "    properties[key] = data['properties'][:, i]\n",
    "    \n",
    "properties['smiles'] = data['smiles_optimized']\n",
    "\n",
    "df = pd.DataFrame(properties)\n",
    "df = df[['smiles'] + labels]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: convert smiles strings into one-hot representation and add to the dataframe in a column named 'one_hot' \n",
    "  \n",
    "hint: use zero padding to make the length equal to MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert SMILES to one-hot here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split to train/validation sets\n",
    "x_train = df.one_hot.values[:-VAL_SIZE]\n",
    "x_val = df.one_hot.values[-VAL_SIZE:]\n",
    "\n",
    "y_train = df[labels].values[:-VAL_SIZE]\n",
    "y_val = df[labels].values[-VAL_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Task 2: define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(MAX_LEN, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build your model here.\n",
    "Eventually the variable 'outputs' should be a list of all the model outputs, one for each task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model and set loss function and metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define your loss function here\n",
    "\"\"\"\n",
    "loss = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define metrics\n",
    "metrics = [MSE, explained_variance_score, r2_score]\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=loss,\n",
    "              metrics=metrics,\n",
    "              optimizer=SGD(lr=LEARNING_RATE, nesterov=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "callbacks = [ReduceLROnPlateau(factor=.2, patience=4, verbose=1),\n",
    "             EarlyStopping(monitor='val_loss', patience=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('##### Model Evaluation #####')\n",
    "print('Mean Squared Error: %f' % MSE(y_true=y_val, y_pred=y_pred))\n",
    "print('Explained Variance: %f' % explained_variance_score(y_true=y_val, y_pred=y_pred))\n",
    "print('R2 Score: %f' % r2_score(y_true=y_val, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
